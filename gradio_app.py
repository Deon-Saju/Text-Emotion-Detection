# -*- coding: utf-8 -*-
"""Gradio_App.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zbQxBTA7u4NVc44s38rFGDepDGimaVxP
"""

!pip install -q gradio transformers torch

from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
import gradio as gr
from pathlib import Path

from google.colab import drive
drive.mount('/content/drive')

model_dir = Path("/content/drive/MyDrive/emotion_model_saved")

tokenizer = AutoTokenizer.from_pretrained(str(model_dir), local_files_only=True)
model = AutoModelForSequenceClassification.from_pretrained(str(model_dir), local_files_only=True)

# Build pipeline from loaded objects only (no path)
emotion_classifier = pipeline(
    "text-classification",
    model=model,
    tokenizer=tokenizer,
    return_all_scores=True
)

# Label mapping
label_names = ["sadness", "joy", "love", "anger", "fear", "surprise"]

# Prediction function
def predict_emotion(text):
    preds = emotion_classifier(text)[0]
    preds_sorted = sorted(preds, key=lambda x: x["score"], reverse=True)
    results = {
        label_names[int(p["label"].split("_")[-1])]: float(p["score"])
        for p in preds_sorted
    }
    return results

# Gradio interface
demo = gr.Interface(
    fn=predict_emotion,
    inputs=gr.Textbox(label="üí¨ Enter a sentence or tweet"),
    outputs=gr.Label(num_top_classes=3, label="Predicted Emotions"),
    title="Emotion Detector ü§ñüí≠",
    description="Detect emotions in text using your fine-tuned Transformer model!",
    theme="soft",
    examples=[
        ["I‚Äôm feeling amazing today!"],
        ["I hate when people lie."],
        ["You make me feel loved ‚ù§Ô∏è"],
        ["That movie scared me a lot!"]
    ]
)

demo.launch(share=True)